{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing basic libraries for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from mappings import contraction_mapping, chat_words_replacements,airport_codes\n",
    "from SW import stopwords_airline, negative_words, stopwords_extra\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | Flight was punctual. But no ...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My sister, niece and mother...</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Mangalore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | My 77-year-old father was fl...</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>Not Verified |  IndiGo are a low cost airline ...</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Jaipur to Ahmedabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My flight 6e 1176 which was...</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Colombo to Mumbai via Chennai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Country                                             Review  \\\n",
       "0  indigo-airlines   India  ✅ Trip Verified | Flight was punctual. But no ...   \n",
       "1  indigo-airlines   India  ✅ Trip Verified |  My sister, niece and mother...   \n",
       "2  indigo-airlines   India  ✅ Trip Verified | My 77-year-old father was fl...   \n",
       "3  indigo-airlines   India  Not Verified |  IndiGo are a low cost airline ...   \n",
       "4  indigo-airlines   India  ✅ Trip Verified |  My flight 6e 1176 which was...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  \\\n",
       "0     2023-05-10      Solo Leisure  Economy Class   \n",
       "1     2023-05-07    Family Leisure  Economy Class   \n",
       "2     2023-04-28      Solo Leisure  Economy Class   \n",
       "3     2023-04-24      Solo Leisure  Economy Class   \n",
       "4     2023-04-22    Family Leisure  Economy Class   \n",
       "\n",
       "                           Route  Seat Comfort  Cabin Staff Service  \\\n",
       "0             Abu Dhabi to Kochi           1.0                  1.0   \n",
       "1            Mumbai to Mangalore           1.0                  NaN   \n",
       "2             Abu Dhabi to Kochi           2.0                  2.0   \n",
       "3            Jaipur to Ahmedabad           2.0                  2.0   \n",
       "4  Colombo to Mumbai via Chennai           1.0                  1.0   \n",
       "\n",
       "   Food & Beverages  Inflight Entertainment  Ground Service  Value for Money  \\\n",
       "0               1.0                     NaN             3.0              1.0   \n",
       "1               NaN                     NaN             1.0              1.0   \n",
       "2               NaN                     NaN             2.0              4.0   \n",
       "3               NaN                     NaN             2.0              3.0   \n",
       "4               1.0                     1.0             1.0              1.0   \n",
       "\n",
       "  Recommended  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3         yes  \n",
       "4          no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the csv file\n",
    "df = pd.read_csv('airline_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15220 entries, 0 to 15219\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Airline                 15220 non-null  object \n",
      " 1   Country                 15220 non-null  object \n",
      " 2   Review                  15220 non-null  object \n",
      " 3   Date_Published          15220 non-null  object \n",
      " 4   Type of Traveller       10974 non-null  object \n",
      " 5   Seat Type               15047 non-null  object \n",
      " 6   Route                   10962 non-null  object \n",
      " 7   Seat Comfort            14222 non-null  float64\n",
      " 8   Cabin Staff Service     14208 non-null  float64\n",
      " 9   Food & Beverages        13085 non-null  float64\n",
      " 10  Inflight Entertainment  11762 non-null  float64\n",
      " 11  Ground Service          10720 non-null  float64\n",
      " 12  Value for Money         15044 non-null  float64\n",
      " 13  Recommended             15220 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Service            4500\n",
       "Route                     4258\n",
       "Type of Traveller         4246\n",
       "Inflight Entertainment    3458\n",
       "Food & Beverages          2135\n",
       "Cabin Staff Service       1012\n",
       "Seat Comfort               998\n",
       "Value for Money            176\n",
       "Seat Type                  173\n",
       "Airline                      0\n",
       "Country                      0\n",
       "Review                       0\n",
       "Date_Published               0\n",
       "Recommended                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords Collection Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n"
     ]
    }
   ],
   "source": [
    "# Joining the stopwords to make a big stopwords collection\n",
    "\n",
    "stopwords = set(stopwords_airline).union(set(negative_words)).union(set(stopwords_extra)).union(nlp.Defaults.stop_words)\n",
    "\n",
    "# For sentiment analysis, we will need negative words as well. So, we have to remove the negative words from the stopwords list\n",
    "\n",
    "stopwords = set([word for word in stopwords if word not in negative_words])\n",
    "\n",
    "print(len(stopwords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  ['Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Ground Service', 'Value for Money']\n",
      "Categorical Columns:  ['Airline', 'Country', 'Type of Traveller', 'Seat Type', 'Recommended']\n",
      "Object Columns:  ['Airline', 'Country', 'Review', 'Date_Published', 'Type of Traveller', 'Seat Type', 'Route', 'Recommended']\n"
     ]
    }
   ],
   "source": [
    "# Separating the numerical and categorical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "obj_col = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_col = [x for x in obj_col if df[x].nunique() < 21]\n",
    "\n",
    "print('Numerical Columns: ',num_col)\n",
    "print('Categorical Columns: ',cat_col)\n",
    "print('Object Columns: ',obj_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_dataframe(df):\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    df[num_col] = imputer.fit_transform(df[num_col])\n",
    "\n",
    "    # As well as changing the data type of the numerical columns to int8\n",
    "    \n",
    "    df[num_col] = df[num_col].astype('int8')\n",
    "    \n",
    "    # Changing the Date_Published column to datetime format\n",
    "\n",
    "    df['Date_Published'] = pd.to_datetime(df['Date_Published'])\n",
    "    \n",
    "    # Sort the data by Airline and Date_Published so that we can fill the missing values in the categorical columns\n",
    "\n",
    "    df.sort_values(by=['Airline','Date_Published'],inplace=True)\n",
    "    \n",
    "    # Imputing the missing values in the categorical columns with mode using Backward fill\n",
    "    \n",
    "    df[obj_col] = df[obj_col].fillna(method='bfill')\n",
    "\n",
    "    # Mapping Recommended to 1 and Not Recommended to 0\n",
    "    \n",
    "    df['Recommended'] = df['Recommended'].replace({'yes':1,'no':0})\n",
    "\n",
    "    # As well as changing the data type of the categorical columns to category\n",
    "    \n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "    \n",
    "    # lastly dropping the duplicate records\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Preprocessing the Airline column\n",
    "\n",
    "    df['Airline'] = df['Airline'].apply(lambda x: re.sub(r'-',' ',x))\n",
    "    df['Airline'] = df['Airline'].str.title()\n",
    "    \n",
    "    # Creating a new column for Overall Rating\n",
    "    \n",
    "    df['Overall_Rating'] = df[num_col].mean(axis=1).round(2)\n",
    "    \n",
    "    # Creating a new column for Sentiment where 1 is positive and 0 is negative sentiment\n",
    "    \n",
    "    df['Sentiment'] = df['Overall_Rating'].apply(lambda x: 1 if x > 3 else (0 if x < 3 else 2))\n",
    "    \n",
    "    # Dropping the records having neutral sentiment\n",
    "    \n",
    "    df = df[df['Sentiment'] != 2]\n",
    "    \n",
    "    # Resetting the index and dropping the Route column\n",
    "    \n",
    "    df.drop(['Route'],axis=1,inplace=True)    \n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = cleanse_dataframe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \n",
    "    # Split on the basis of '|'\n",
    "    text = text.split('|')\n",
    "\n",
    "    # Check length and take the appropriate part\n",
    "    if len(text) == 2:\n",
    "        text = text[-1]\n",
    "    else:\n",
    "        text = text[0]\n",
    "        \n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'-')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Remove brackets\n",
    "    brackets = re.compile(r'[()[\\]{}!@#^&*]')\n",
    "    text = brackets.sub(r'', text)\n",
    "    \n",
    "    # Map Airport Codes to Country Names\n",
    "    text = \" \".join([airport_codes[t] if t in airport_codes else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002500-\\U00002BEF\"  # chinese characters\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Remove special characters: newlines, tabs, etc.\n",
    "    text = re.sub(r'\\n|\\t|\\r', '', text)\n",
    "\n",
    "    # Map contractions to expansions\n",
    "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])\n",
    "\n",
    "    # Map chat words to formal words\n",
    "    text = \" \".join([chat_words_replacements[t] if t in chat_words_replacements else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(r' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flair Sentiment Analysis\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('sentiment-fast')\n",
    "\n",
    "def flair_sentiment(text):\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "    return sentence.labels[0].value\n",
    "\n",
    "df['Sentiment_Flair'] = df['Review'].apply(flair_sentiment)\n",
    "\n",
    "df['Sentiment_Flair'] = df['Sentiment_Flair'].apply(lambda x: 1 if x == 'POSITIVE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Length:  686\n",
      "Minimum Review Length:  14\n",
      "Average Review Length:  129.50051268029256\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column for the length of the review\n",
    "\n",
    "df['Review_Length'] = df['Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('Maximum Review Length: ',df['Review_Length'].max())\n",
    "print('Minimum Review Length: ',df['Review_Length'].min())\n",
    "print('Average Review Length: ',df['Review_Length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the reviews using spacy\n",
    "\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['Cleaned_Review'] = df['Review'].apply(lemmatizer)\n",
    "# Remvoing the stopwords from the reviews\n",
    "\n",
    "df['Cleaned_Review'] = df['Cleaned_Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Length:  390\n",
      "Minimum Review Length:  8\n",
      "Average Review Length:  69.56620411511382\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column for the length of the review\n",
    "\n",
    "df['Cleaned_Review_Length'] = df['Cleaned_Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('Maximum Review Length: ',df['Cleaned_Review_Length'].max())\n",
    "print('Minimum Review Length: ',df['Cleaned_Review_Length'].min())\n",
    "print('Average Review Length: ',df['Cleaned_Review_Length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('airline_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
