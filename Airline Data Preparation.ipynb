{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing basic libraries for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from mappings import contraction_mapping, chat_words_replacements,airport_codes,origin_loc_mapping,dest_loc_mapping\n",
    "sns.set_theme()\n",
    "\n",
    "# Setting the best style for the plots in seaborn\n",
    "\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | Flight was punctual. But no ...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My sister, niece and mother...</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Mangalore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | My 77-year-old father was fl...</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>Not Verified |  IndiGo are a low cost airline ...</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Jaipur to Ahmedabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My flight 6e 1176 which was...</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Colombo to Mumbai via Chennai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Country                                             Review  \\\n",
       "0  indigo-airlines   India  ✅ Trip Verified | Flight was punctual. But no ...   \n",
       "1  indigo-airlines   India  ✅ Trip Verified |  My sister, niece and mother...   \n",
       "2  indigo-airlines   India  ✅ Trip Verified | My 77-year-old father was fl...   \n",
       "3  indigo-airlines   India  Not Verified |  IndiGo are a low cost airline ...   \n",
       "4  indigo-airlines   India  ✅ Trip Verified |  My flight 6e 1176 which was...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  \\\n",
       "0     2023-05-10      Solo Leisure  Economy Class   \n",
       "1     2023-05-07    Family Leisure  Economy Class   \n",
       "2     2023-04-28      Solo Leisure  Economy Class   \n",
       "3     2023-04-24      Solo Leisure  Economy Class   \n",
       "4     2023-04-22    Family Leisure  Economy Class   \n",
       "\n",
       "                           Route  Seat Comfort  Cabin Staff Service  \\\n",
       "0             Abu Dhabi to Kochi           1.0                  1.0   \n",
       "1            Mumbai to Mangalore           1.0                  NaN   \n",
       "2             Abu Dhabi to Kochi           2.0                  2.0   \n",
       "3            Jaipur to Ahmedabad           2.0                  2.0   \n",
       "4  Colombo to Mumbai via Chennai           1.0                  1.0   \n",
       "\n",
       "   Food & Beverages  Inflight Entertainment  Ground Service  Value for Money  \\\n",
       "0               1.0                     NaN             3.0              1.0   \n",
       "1               NaN                     NaN             1.0              1.0   \n",
       "2               NaN                     NaN             2.0              4.0   \n",
       "3               NaN                     NaN             2.0              3.0   \n",
       "4               1.0                     1.0             1.0              1.0   \n",
       "\n",
       "  Recommended  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3         yes  \n",
       "4          no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the csv file\n",
    "df = pd.read_csv('airline_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>10974</td>\n",
       "      <td>15047</td>\n",
       "      <td>10962</td>\n",
       "      <td>14222.000000</td>\n",
       "      <td>14208.000000</td>\n",
       "      <td>13085.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "      <td>10720.000000</td>\n",
       "      <td>15044.000000</td>\n",
       "      <td>15220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>15205</td>\n",
       "      <td>3718</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>emirates</td>\n",
       "      <td>India</td>\n",
       "      <td>Manchester to Doha and then Bangkok 24th Janua...</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Guangzhou to Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2266</td>\n",
       "      <td>3640</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>4534</td>\n",
       "      <td>11214</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.425116</td>\n",
       "      <td>3.588401</td>\n",
       "      <td>3.343676</td>\n",
       "      <td>3.432409</td>\n",
       "      <td>3.213433</td>\n",
       "      <td>3.372108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390692</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>1.439589</td>\n",
       "      <td>1.408876</td>\n",
       "      <td>1.637206</td>\n",
       "      <td>1.533749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Airline Country                                             Review  \\\n",
       "count      15220   15220                                              15220   \n",
       "unique        19       9                                              15205   \n",
       "top     emirates   India  Manchester to Doha and then Bangkok 24th Janua...   \n",
       "freq        2266    3640                                                  2   \n",
       "mean         NaN     NaN                                                NaN   \n",
       "std          NaN     NaN                                                NaN   \n",
       "min          NaN     NaN                                                NaN   \n",
       "25%          NaN     NaN                                                NaN   \n",
       "50%          NaN     NaN                                                NaN   \n",
       "75%          NaN     NaN                                                NaN   \n",
       "max          NaN     NaN                                                NaN   \n",
       "\n",
       "       Date_Published Type of Traveller      Seat Type                Route  \\\n",
       "count           15220             10974          15047                10962   \n",
       "unique           3718                 4              4                 6716   \n",
       "top        2015-01-14      Solo Leisure  Economy Class  Guangzhou to Sydney   \n",
       "freq               39              4534          11214                   30   \n",
       "mean              NaN               NaN            NaN                  NaN   \n",
       "std               NaN               NaN            NaN                  NaN   \n",
       "min               NaN               NaN            NaN                  NaN   \n",
       "25%               NaN               NaN            NaN                  NaN   \n",
       "50%               NaN               NaN            NaN                  NaN   \n",
       "75%               NaN               NaN            NaN                  NaN   \n",
       "max               NaN               NaN            NaN                  NaN   \n",
       "\n",
       "        Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "count   14222.000000         14208.000000      13085.000000   \n",
       "unique           NaN                  NaN               NaN   \n",
       "top              NaN                  NaN               NaN   \n",
       "freq             NaN                  NaN               NaN   \n",
       "mean        3.425116             3.588401          3.343676   \n",
       "std         1.390692             1.524603          1.439589   \n",
       "min         1.000000             1.000000          1.000000   \n",
       "25%         2.000000             2.000000          2.000000   \n",
       "50%         4.000000             4.000000          4.000000   \n",
       "75%         5.000000             5.000000          5.000000   \n",
       "max         5.000000             5.000000          5.000000   \n",
       "\n",
       "        Inflight Entertainment  Ground Service  Value for Money Recommended  \n",
       "count             11762.000000    10720.000000     15044.000000       15220  \n",
       "unique                     NaN             NaN              NaN           2  \n",
       "top                        NaN             NaN              NaN         yes  \n",
       "freq                       NaN             NaN              NaN        8913  \n",
       "mean                  3.432409        3.213433         3.372108         NaN  \n",
       "std                   1.408876        1.637206         1.533749         NaN  \n",
       "min                   1.000000        1.000000         1.000000         NaN  \n",
       "25%                   2.000000        1.000000         2.000000         NaN  \n",
       "50%                   4.000000        4.000000         4.000000         NaN  \n",
       "75%                   5.000000        5.000000         5.000000         NaN  \n",
       "max                   5.000000        5.000000         5.000000         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15220 entries, 0 to 15219\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Airline                 15220 non-null  object \n",
      " 1   Country                 15220 non-null  object \n",
      " 2   Review                  15220 non-null  object \n",
      " 3   Date_Published          15220 non-null  object \n",
      " 4   Type of Traveller       10974 non-null  object \n",
      " 5   Seat Type               15047 non-null  object \n",
      " 6   Route                   10962 non-null  object \n",
      " 7   Seat Comfort            14222 non-null  float64\n",
      " 8   Cabin Staff Service     14208 non-null  float64\n",
      " 9   Food & Beverages        13085 non-null  float64\n",
      " 10  Inflight Entertainment  11762 non-null  float64\n",
      " 11  Ground Service          10720 non-null  float64\n",
      " 12  Value for Money         15044 non-null  float64\n",
      " 13  Recommended             15220 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Service            4500\n",
       "Route                     4258\n",
       "Type of Traveller         4246\n",
       "Inflight Entertainment    3458\n",
       "Food & Beverages          2135\n",
       "Cabin Staff Service       1012\n",
       "Seat Comfort               998\n",
       "Value for Money            176\n",
       "Seat Type                  173\n",
       "Airline                      0\n",
       "Country                      0\n",
       "Review                       0\n",
       "Date_Published               0\n",
       "Recommended                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  ['Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Ground Service', 'Value for Money']\n",
      "Categorical Columns:  ['Airline', 'Country', 'Type of Traveller', 'Seat Type', 'Recommended']\n"
     ]
    }
   ],
   "source": [
    "# Separating the numerical and categorical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "obj_col = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_col = [x for x in obj_col if df[x].nunique() < 21]\n",
    "\n",
    "print('Numerical Columns: ',num_col)\n",
    "print('Categorical Columns: ',cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indigo-airlines' 'vistara' 'spicejet' 'airasia-india' 'air-india'\n",
      " 'air-india-express' 'goair' 'emirates' 'china-eastern-airlines'\n",
      " 'air-china' 'qatar-airways' 'lion-air' 'japan-airlines' 'vietjetair'\n",
      " 'korean-air' 'singapore-airlines' 'ana-all-nippon-airways'\n",
      " 'china-southern-airlines' 'jet-airways']\n",
      "['India' 'UAE' 'China' 'Qatar' 'Indonesia' 'Japan' 'Vietnam' 'South Korea'\n",
      " 'Singapore']\n",
      "['✅ Trip Verified | Flight was punctual. But no comfortable seating, the crew do not care about the passengers at all. I did not book food. The crew did not ask passengers whether they need food or not. Alcohol they gave to many people for a price.'\n",
      " \"✅ Trip Verified |  My sister, niece and mother were traveling by Indigo flight. I had booked wheelchair assistance and it was mentioned that the wheelchair assistance was in waiting list. When they reached the airport it was mentioned no wheel chair assistance would be provided. They reached the airport close to 3 hrs in advance. The front desk did not even help with other paid assistance wheelchairs. They simply ignored my sister's requests. Departure was at gate 85, later it was changed to Gate 35 at last minute Again my mother had to walk such long distance without any assistance from the airline crew. At least the crew could have guided the family to a paid wheel chair assistance at Mumbai airport.\"\n",
      " \"✅ Trip Verified | My 77-year-old father was flying Indigo from Abu Dhabi to Kochi, 6E 1404. It was delayed by more than 1.5 hours last night and as scheduled, it was due to depart from Abu Dhabi Terminal 1. After arriving at the airport, we then found out that check-in was moved to T3 and boarding was back at T1. My father faced a lot of inconvenience in lost time and stress due to which he couldn't use the lounge prior to departure. Very frustrated with\\xa0Indigo Airlines.\"\n",
      " ...\n",
      " \"SYD-MEL-SYD. It's hard to fault their in-flight service. 60 seats all business-class. Their pre and after-sales services needs refining. Having already had a schedule change notification a few days before the SYD-MEL leg I was annoyed and frustrated to wake up on the morning of the flight driving from Canberra to Sydney to get another message they had left very late the night before telling me that the 9am flight had been cancelled - and I'd been put on the 8am flight instead. That might have been fine if I'd lived in Sydney but it made the drive up to Sydney from Canberra fast and furious! I tried many times to contact OzJet's customer service line after their 6am opening but couldn't - it took them to call me at 6:45am before they realised their incoming call line had not been activated for the morning! When I arrived in Sydney I had to use valet parking ($139) in order to make my flight. Before the return leg I logged on to check the flight details only to find the MEL-SYD portion had mysteriously disappeared from my online itinerary. After ringing them I was told that it had been a mistake; they had deleted that portion instead of the cancelled flight a few days earlier! I was put back on the flight but really business won't wear this sort of inconvenience.\"\n",
      " 'MEL-SYD return. 737-200 both ways. Clean aircraft. Nice big seats. Meals good and full bar service. Cabin staff very friendly and always around - but they only had about 20 people to look after as the plane was mostly empty. I would fly OZJet again.'\n",
      " \"MEL-SYD. The jet was immaculate as was the cabin crew. The seats were huge - same as traditional business class seats and leg room was more than generous. We received a glass of champagne and a choice of other drinks. A full meal was provided - great quality. The cabin crew were attentive and nothing was too much trouble. There were only 12 people on the flight which was a bizarre experience - we got a really good deal on the flight and I'm shocked that more people aren't trying it. It made flying fun and enjoyable again it really did.\"]\n",
      "['2023-05-10' '2023-05-07' '2023-04-28' ... '2006-02-13' '2006-01-26'\n",
      " '2006-01-12']\n",
      "['Solo Leisure' 'Family Leisure' 'Business' 'Couple Leisure' nan]\n",
      "['Economy Class' 'Premium Economy' 'Business Class' 'First Class' nan]\n",
      "['Abu Dhabi to Kochi' 'Mumbai to Mangalore' 'Jaipur to Ahmedabad' ...\n",
      " 'Bangalore to Singapore via Chennai'\n",
      " 'London Heathrow to Chennai via Mumbai' 'Mumbai to Hong Kong']\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "for i in obj_col:\n",
    "        # Print all the unique values in the column\n",
    "        print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing values in the numerical columns with mode using simple imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def cleanse_data(df):    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    df[num_col] = imputer.fit_transform(df[num_col])\n",
    "\n",
    "    # As well as changing the data type of the numerical columns to int8\n",
    "    \n",
    "    df[num_col] = df[num_col].astype('int8')\n",
    "    \n",
    "    # Changing the Date_Published column to datetime format\n",
    "\n",
    "    df['Date_Published'] = pd.to_datetime(df['Date_Published'])\n",
    "    \n",
    "    # Sort the data by Airline and Date_Published so that we can fill the missing values in the categorical columns\n",
    "\n",
    "    df.sort_values(by=['Airline','Date_Published'],inplace=True)\n",
    "    \n",
    "    # Imputing the missing values in the categorical columns with mode using Backward fill\n",
    "    \n",
    "    df[obj_col] = df[obj_col].fillna(method='bfill')\n",
    "\n",
    "    # Mapping Recommended to 1 and Not Recommended to 0\n",
    "    \n",
    "    df['Recommended'] = df['Recommended'].map({'yes':1,'no':0})\n",
    "\n",
    "    # As well as changing the data type of the categorical columns to category\n",
    "    \n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "\n",
    "    # Cleaning the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].apply(lambda x: x.split('via')[0].strip() if 'via' in x else x.strip())\n",
    "\n",
    "    # Dropping the record where the route is Melbourne, Chennai and Zurich\n",
    "    \n",
    "    df.drop(df[df['Route'] == 'Melbourne'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Chennai'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Zurich'].index, inplace=True)\n",
    "\n",
    "    # Small casing the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].str.lower()\n",
    "    \n",
    "    # ro, to, yo, - will be used for splitting the route column\n",
    "\n",
    "    # Splitting the Route column into Origin and Destination\n",
    "\n",
    "    # Origin Extraction\n",
    "\n",
    "    df['Origin'] = df['Route'].apply(lambda x: x.split('ro')[0].strip() if 'ro' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('to')[0].strip() if 'to' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('yo')[0].strip() if 'yo' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('-')[0].strip() if '-' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].str.capitalize()\n",
    "\n",
    "    # Destination Extraction\n",
    "\n",
    "    df['Destination'] = df['Route'].apply(lambda x: x.split('ro')[-1].strip() if 'ro' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('to')[-1].strip() if 'to' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('yo')[-1].strip() if 'yo' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('-')[-1].strip() if '-' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].str.capitalize()\n",
    "\n",
    "    # lastly dropping the\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Preprocessing the Airline column\n",
    "\n",
    "    df['Airline'] = df['Airline'].apply(lambda x: re.sub(r'-',' ',x))\n",
    "    df['Airline'] = df['Airline'].str.title()\n",
    "\n",
    "    # df.drop(['Route'],axis=1,inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    df['Sentiment'] = df['Recommended'].map({1:'Positive',0:'Negative'})\n",
    "    \n",
    "    # Capitalizing the first letter of the Origin and Destination columns\n",
    "    \n",
    "    df['Origin'] = df['Origin'].str.title()\n",
    "    df['Destination'] = df['Destination'].str.title()\n",
    "    \n",
    "    # # Mapping the Origin and Destination columns to their respective countries without map function\n",
    "    \n",
    "    df['Origin'] = df['Origin'].apply(lambda x: origin_loc_mapping[x] if x in origin_loc_mapping.keys() else x)    \n",
    "    df['Destination'] = df['Destination'].apply(lambda x: dest_loc_mapping[x] if x in dest_loc_mapping.keys() else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = cleanse_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "print(df['Origin'].nunique())\n",
    "print(df['Destination'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \n",
    "    # Substitute - with 'to'\n",
    "    \n",
    "    text = re.sub(r'-',' to ',text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Map Airport Codes to Country Names\n",
    "    text = \" \".join([airport_codes[t] if t in airport_codes else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002500-\\U00002BEF\"  # chinese characters\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Split on the basis of '|'\n",
    "    text = text.split('|')\n",
    "\n",
    "    # Check length and take the appropriate part\n",
    "    if len(text) == 2:\n",
    "        text = text[-1]\n",
    "    else:\n",
    "        text = text[0]\n",
    "\n",
    "    # Remove special characters: newlines, tabs, etc.\n",
    "    text = re.sub(r'\\n|\\t|\\r', '', text)\n",
    "\n",
    "    # Map contractions to expansions\n",
    "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])\n",
    "\n",
    "    # Map chat words to formal words\n",
    "    text = \" \".join([chat_words_replacements[t] if t in chat_words_replacements else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(r' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(lambda x: text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>los angeles to beijing return. food low qualit...</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>beijing to xi'an</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>round to trip from hong kong to munich. the ma...</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>beijing to xi'an</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>sydney to beijing to paris then rome to beijin...</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>beijing to xi'an</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>london to sydney return via beijing. a cheap f...</td>\n",
       "      <td>2012-02-22</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>beijing to xi'an</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>beijing to shanghai. only one check to in desk...</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>beijing to xi'an</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airline Country                                             Review  \\\n",
       "0  Air China   China  los angeles to beijing return. food low qualit...   \n",
       "1  Air China   China  round to trip from hong kong to munich. the ma...   \n",
       "2  Air China   China  sydney to beijing to paris then rome to beijin...   \n",
       "3  Air China   China  london to sydney return via beijing. a cheap f...   \n",
       "4  Air China   China  beijing to shanghai. only one check to in desk...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type             Route  \\\n",
       "0     2012-01-30      Solo Leisure  Economy Class  beijing to xi'an   \n",
       "1     2012-01-31      Solo Leisure  Economy Class  beijing to xi'an   \n",
       "2     2012-02-03      Solo Leisure  Economy Class  beijing to xi'an   \n",
       "3     2012-02-22      Solo Leisure  Economy Class  beijing to xi'an   \n",
       "4     2012-02-28      Solo Leisure  Economy Class  beijing to xi'an   \n",
       "\n",
       "   Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "0             3                    2                 2   \n",
       "1             1                    3                 1   \n",
       "2             2                    3                 1   \n",
       "3             4                    1                 2   \n",
       "4             4                    4                 3   \n",
       "\n",
       "   Inflight Entertainment  Ground Service  Value for Money Recommended Origin  \\\n",
       "0                       1               1                3           0  China   \n",
       "1                       1               1                3           0  China   \n",
       "2                       2               1                3           0  China   \n",
       "3                       4               3                4           0  China   \n",
       "4                       3               3                4           1  China   \n",
       "\n",
       "  Destination Sentiment  \n",
       "0       China  Negative  \n",
       "1       China  Negative  \n",
       "2       China  Negative  \n",
       "3       China  Negative  \n",
       "4       China  Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Plotting the distribution of the numerical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(15,15))\n",
    "\n",
    "for i, subplot in zip(num_col, ax.flatten()):\n",
    "    sns.distplot(df[i], ax=subplot)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the distribution of the categorical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(20,15))\n",
    "\n",
    "for i, subplot in zip(cat_col, ax.flatten()):\n",
    "    sns.countplot(x=i,data=df, ax=subplot, palette='CMRmap_r')\n",
    "    if i in ['Airline','Country']:\n",
    "        for label in subplot.get_xticklabels():\n",
    "            label.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Origin_Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Origin_Country'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mOrigin_Country\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Print the unique values in the columns\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mprint\u001b[39m(i,df[i]\u001b[39m.\u001b[39munique())\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Origin_Country'"
     ]
    }
   ],
   "source": [
    "for i in ['Origin_Country','Destination']:\n",
    "    # Print the unique values in the columns\n",
    "    print(i,df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('airline_df_cleaned.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
