{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing basic libraries for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from mappings import contraction_mapping, chat_words_replacements,airport_codes\n",
    "sns.set_theme()\n",
    "\n",
    "# Setting the best style for the plots in seaborn\n",
    "\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | Flight was punctual. But no ...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My sister, niece and mother...</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Mangalore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | My 77-year-old father was fl...</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>Not Verified |  IndiGo are a low cost airline ...</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Jaipur to Ahmedabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My flight 6e 1176 which was...</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Colombo to Mumbai via Chennai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Country                                             Review  \\\n",
       "0  indigo-airlines   India  ✅ Trip Verified | Flight was punctual. But no ...   \n",
       "1  indigo-airlines   India  ✅ Trip Verified |  My sister, niece and mother...   \n",
       "2  indigo-airlines   India  ✅ Trip Verified | My 77-year-old father was fl...   \n",
       "3  indigo-airlines   India  Not Verified |  IndiGo are a low cost airline ...   \n",
       "4  indigo-airlines   India  ✅ Trip Verified |  My flight 6e 1176 which was...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  \\\n",
       "0     2023-05-10      Solo Leisure  Economy Class   \n",
       "1     2023-05-07    Family Leisure  Economy Class   \n",
       "2     2023-04-28      Solo Leisure  Economy Class   \n",
       "3     2023-04-24      Solo Leisure  Economy Class   \n",
       "4     2023-04-22    Family Leisure  Economy Class   \n",
       "\n",
       "                           Route  Seat Comfort  Cabin Staff Service  \\\n",
       "0             Abu Dhabi to Kochi           1.0                  1.0   \n",
       "1            Mumbai to Mangalore           1.0                  NaN   \n",
       "2             Abu Dhabi to Kochi           2.0                  2.0   \n",
       "3            Jaipur to Ahmedabad           2.0                  2.0   \n",
       "4  Colombo to Mumbai via Chennai           1.0                  1.0   \n",
       "\n",
       "   Food & Beverages  Inflight Entertainment  Ground Service  Value for Money  \\\n",
       "0               1.0                     NaN             3.0              1.0   \n",
       "1               NaN                     NaN             1.0              1.0   \n",
       "2               NaN                     NaN             2.0              4.0   \n",
       "3               NaN                     NaN             2.0              3.0   \n",
       "4               1.0                     1.0             1.0              1.0   \n",
       "\n",
       "  Recommended  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3         yes  \n",
       "4          no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the csv file\n",
    "df = pd.read_csv('airline_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>10974</td>\n",
       "      <td>15047</td>\n",
       "      <td>10962</td>\n",
       "      <td>14222.000000</td>\n",
       "      <td>14208.000000</td>\n",
       "      <td>13085.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "      <td>10720.000000</td>\n",
       "      <td>15044.000000</td>\n",
       "      <td>15220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>15205</td>\n",
       "      <td>3718</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>emirates</td>\n",
       "      <td>India</td>\n",
       "      <td>Manchester to Doha and then Bangkok 24th Janua...</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Guangzhou to Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2266</td>\n",
       "      <td>3640</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>4534</td>\n",
       "      <td>11214</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.425116</td>\n",
       "      <td>3.588401</td>\n",
       "      <td>3.343676</td>\n",
       "      <td>3.432409</td>\n",
       "      <td>3.213433</td>\n",
       "      <td>3.372108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390692</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>1.439589</td>\n",
       "      <td>1.408876</td>\n",
       "      <td>1.637206</td>\n",
       "      <td>1.533749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Airline Country                                             Review  \\\n",
       "count      15220   15220                                              15220   \n",
       "unique        19       9                                              15205   \n",
       "top     emirates   India  Manchester to Doha and then Bangkok 24th Janua...   \n",
       "freq        2266    3640                                                  2   \n",
       "mean         NaN     NaN                                                NaN   \n",
       "std          NaN     NaN                                                NaN   \n",
       "min          NaN     NaN                                                NaN   \n",
       "25%          NaN     NaN                                                NaN   \n",
       "50%          NaN     NaN                                                NaN   \n",
       "75%          NaN     NaN                                                NaN   \n",
       "max          NaN     NaN                                                NaN   \n",
       "\n",
       "       Date_Published Type of Traveller      Seat Type                Route  \\\n",
       "count           15220             10974          15047                10962   \n",
       "unique           3718                 4              4                 6716   \n",
       "top        2015-01-14      Solo Leisure  Economy Class  Guangzhou to Sydney   \n",
       "freq               39              4534          11214                   30   \n",
       "mean              NaN               NaN            NaN                  NaN   \n",
       "std               NaN               NaN            NaN                  NaN   \n",
       "min               NaN               NaN            NaN                  NaN   \n",
       "25%               NaN               NaN            NaN                  NaN   \n",
       "50%               NaN               NaN            NaN                  NaN   \n",
       "75%               NaN               NaN            NaN                  NaN   \n",
       "max               NaN               NaN            NaN                  NaN   \n",
       "\n",
       "        Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "count   14222.000000         14208.000000      13085.000000   \n",
       "unique           NaN                  NaN               NaN   \n",
       "top              NaN                  NaN               NaN   \n",
       "freq             NaN                  NaN               NaN   \n",
       "mean        3.425116             3.588401          3.343676   \n",
       "std         1.390692             1.524603          1.439589   \n",
       "min         1.000000             1.000000          1.000000   \n",
       "25%         2.000000             2.000000          2.000000   \n",
       "50%         4.000000             4.000000          4.000000   \n",
       "75%         5.000000             5.000000          5.000000   \n",
       "max         5.000000             5.000000          5.000000   \n",
       "\n",
       "        Inflight Entertainment  Ground Service  Value for Money Recommended  \n",
       "count             11762.000000    10720.000000     15044.000000       15220  \n",
       "unique                     NaN             NaN              NaN           2  \n",
       "top                        NaN             NaN              NaN         yes  \n",
       "freq                       NaN             NaN              NaN        8913  \n",
       "mean                  3.432409        3.213433         3.372108         NaN  \n",
       "std                   1.408876        1.637206         1.533749         NaN  \n",
       "min                   1.000000        1.000000         1.000000         NaN  \n",
       "25%                   2.000000        1.000000         2.000000         NaN  \n",
       "50%                   4.000000        4.000000         4.000000         NaN  \n",
       "75%                   5.000000        5.000000         5.000000         NaN  \n",
       "max                   5.000000        5.000000         5.000000         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15220 entries, 0 to 15219\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Airline                 15220 non-null  object \n",
      " 1   Country                 15220 non-null  object \n",
      " 2   Review                  15220 non-null  object \n",
      " 3   Date_Published          15220 non-null  object \n",
      " 4   Type of Traveller       10974 non-null  object \n",
      " 5   Seat Type               15047 non-null  object \n",
      " 6   Route                   10962 non-null  object \n",
      " 7   Seat Comfort            14222 non-null  float64\n",
      " 8   Cabin Staff Service     14208 non-null  float64\n",
      " 9   Food & Beverages        13085 non-null  float64\n",
      " 10  Inflight Entertainment  11762 non-null  float64\n",
      " 11  Ground Service          10720 non-null  float64\n",
      " 12  Value for Money         15044 non-null  float64\n",
      " 13  Recommended             15220 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Service            4500\n",
       "Route                     4258\n",
       "Type of Traveller         4246\n",
       "Inflight Entertainment    3458\n",
       "Food & Beverages          2135\n",
       "Cabin Staff Service       1012\n",
       "Seat Comfort               998\n",
       "Value for Money            176\n",
       "Seat Type                  173\n",
       "Airline                      0\n",
       "Country                      0\n",
       "Review                       0\n",
       "Date_Published               0\n",
       "Recommended                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  ['Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Ground Service', 'Value for Money']\n",
      "Categorical Columns:  ['Airline', 'Country', 'Type of Traveller', 'Seat Type', 'Recommended']\n"
     ]
    }
   ],
   "source": [
    "# Separating the numerical and categorical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "obj_col = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_col = [x for x in obj_col if df[x].nunique() < 21]\n",
    "\n",
    "print('Numerical Columns: ',num_col)\n",
    "print('Categorical Columns: ',cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the missing values in the numerical columns with mode using simple imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def cleanse_data(df):    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    df[num_col] = imputer.fit_transform(df[num_col])\n",
    "\n",
    "    # As well as changing the data type of the numerical columns to int8\n",
    "    \n",
    "    df[num_col] = df[num_col].astype('int8')\n",
    "    \n",
    "    # Changing the Date_Published column to datetime format\n",
    "\n",
    "    df['Date_Published'] = pd.to_datetime(df['Date_Published'])\n",
    "    \n",
    "    # Sort the data by Airline and Date_Published so that we can fill the missing values in the categorical columns\n",
    "\n",
    "    df.sort_values(by=['Airline','Date_Published'],inplace=True)\n",
    "    \n",
    "    # Imputing the missing values in the categorical columns with mode using Backward fill\n",
    "    \n",
    "    df[obj_col] = df[obj_col].fillna(method='bfill')\n",
    "\n",
    "    # Mapping Recommended to 1 and Not Recommended to 0\n",
    "    \n",
    "    df['Recommended'] = df['Recommended'].map({'yes':1,'no':0})\n",
    "\n",
    "    # As well as changing the data type of the categorical columns to category\n",
    "    \n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "\n",
    "    # Cleaning the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].apply(lambda x: x.split('via')[0].strip() if 'via' in x else x.strip())\n",
    "\n",
    "    # Dropping the record where the route is Melbourne, Chennai and Zurich\n",
    "    \n",
    "    df.drop(df[df['Route'] == 'Melbourne'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Chennai'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Zurich'].index, inplace=True)\n",
    "\n",
    "    # Small casing the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].str.lower()\n",
    "    \n",
    "    # ro, to, yo, - will be used for splitting the route column\n",
    "\n",
    "    # Splitting the Route column into Origin and Destination\n",
    "\n",
    "    # Origin Extraction\n",
    "\n",
    "    df['Origin'] = df['Route'].apply(lambda x: x.split('ro')[0].strip() if 'ro' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('to')[0].strip() if 'to' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('yo')[0].strip() if 'yo' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('-')[0].strip() if '-' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].str.capitalize()\n",
    "\n",
    "    # Destination Extraction\n",
    "\n",
    "    df['Destination'] = df['Route'].apply(lambda x: x.split('ro')[-1].strip() if 'ro' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('to')[-1].strip() if 'to' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('yo')[-1].strip() if 'yo' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('-')[-1].strip() if '-' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].str.capitalize()\n",
    "\n",
    "    # lastly dropping the\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Preprocessing the Airline column\n",
    "\n",
    "    df['Airline'] = df['Airline'].apply(lambda x: re.sub(r'-',' ',x))\n",
    "    df['Airline'] = df['Airline'].str.title()\n",
    "\n",
    "    df.drop(['Route'],axis=1,inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    df['Sentiment'] = df['Recommended'].map({1:'Positive',0:'Negative'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = cleanse_data(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ain't\": 'is not', \"aren't\": 'are not', \"can't\": 'cannot', \"'cause\": 'because', \"could've\": 'could have', \"couldn't\": 'could not', \"didn't\": 'did not', \"doesn't\": 'does not', \"don't\": 'do not', \"hadn't\": 'had not', \"hasn't\": 'has not', \"haven't\": 'have not', \"he'd\": 'he would', \"he'll\": 'he will', \"he's\": 'he is', \"how'd\": 'how did', \"how'd'y\": 'how do you', \"how'll\": 'how will', \"how's\": 'how is', \"I'd\": 'I would', \"I'd've\": 'I would have', \"I'll\": 'I will', \"I'll've\": 'I will have', \"I'm\": 'I am', \"I've\": 'I have', \"i'd\": 'i would', \"i'd've\": 'i would have', \"i'll\": 'i will', \"i'll've\": 'i will have', \"i'm\": 'i am', \"i've\": 'i have', \"isn't\": 'is not', \"it'd\": 'it would', \"it'd've\": 'it would have', \"it'll\": 'it will', \"it'll've\": 'it will have', \"it's\": 'it is', \"let's\": 'let us', \"ma'am\": 'madam', \"mayn't\": 'may not', \"might've\": 'might have', \"mightn't\": 'might not', \"mightn't've\": 'might not have', \"must've\": 'must have', \"mustn't\": 'must not', \"mustn't've\": 'must not have', \"needn't\": 'need not', \"needn't've\": 'need not have', \"o'clock\": 'of the clock', \"oughtn't\": 'ought not', \"oughtn't've\": 'ought not have', \"shan't\": 'shall not', \"sha'n't\": 'shall not', \"shan't've\": 'shall not have', \"she'd\": 'she would', \"she'd've\": 'she would have', \"she'll\": 'she will', \"she'll've\": 'she will have', \"she's\": 'she is', \"should've\": 'should have', \"shouldn't\": 'should not', \"shouldn't've\": 'should not have', \"so've\": 'so have', \"so's\": 'so as', \"this's\": 'this is', \"that'd\": 'that would', \"that'd've\": 'that would have', \"that's\": 'that is', \"there'd\": 'there would', \"there'd've\": 'there would have', \"there's\": 'there is', \"here's\": 'here is', \"they'd\": 'they would', \"they'd've\": 'they would have', \"they'll\": 'they will', \"they'll've\": 'they will have', \"they're\": 'they are', \"they've\": 'they have', \"to've\": 'to have', \"wasn't\": 'was not', \"we'd\": 'we would', \"we'd've\": 'we would have', \"we'll\": 'we will', \"we'll've\": 'we will have', \"we're\": 'we are', \"we've\": 'we have', \"weren't\": 'were not', \"what'll\": 'what will', \"what'll've\": 'what will have', \"what're\": 'what are', \"what's\": 'what is', \"what've\": 'what have', \"when's\": 'when is', \"when've\": 'when have', \"where'd\": 'where did', \"where's\": 'where is', \"where've\": 'where have', \"who'll\": 'who will', \"who'll've\": 'who will have', \"who's\": 'who is', \"who've\": 'who have', \"why's\": 'why is', \"why've\": 'why have', \"will've\": 'will have', \"won't\": 'will not', \"won't've\": 'will not have', \"would've\": 'would have', \"wouldn't\": 'would not', \"wouldn't've\": 'would not have', \"y'all\": 'you all', \"y'all'd\": 'you all would', \"y'all'd've\": 'you all would have', \"y'all're\": 'you all are', \"y'all've\": 'you all have', \"you'd\": 'you would', \"you'd've\": 'you would have', \"you'll\": 'you will', \"you'll've\": 'you will have', \"you're\": 'you are', \"you've\": 'you have', 'ws': 'was', 'w': 'with', 'msg': 'message', 'ms': 'miss', 'u': 'you', 'ur': 'your', 'r': 'are', 'b': 'be', 'd': 'the', 'n': 'and', 'k': 'ok', 'kk': 'ok', 'missin': 'missing', 'mr': 'mister', 'mrs': 'misses', 'ms.': 'miss'}\n"
     ]
    }
   ],
   "source": [
    "print(contraction_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \n",
    "    # Substitute - with 'to'\n",
    "    \n",
    "    text = re.sub(r'-',' to ',text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Map Airport Codes to Country Names\n",
    "    text = \" \".join([airport_codes[t] if t in airport_codes else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002500-\\U00002BEF\"  # chinese characters\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Split on the basis of '|'\n",
    "    text = text.split('|')\n",
    "\n",
    "    # Check length and take the appropriate part\n",
    "    if len(text) == 2:\n",
    "        text = text[-1]\n",
    "    else:\n",
    "        text = text[0]\n",
    "\n",
    "    # Remove special characters: newlines, tabs, etc.\n",
    "    text = re.sub(r'\\n|\\t|\\r', '', text)\n",
    "\n",
    "    # Map contractions to expansions\n",
    "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])\n",
    "\n",
    "    # Map chat words to formal words\n",
    "    text = \" \".join([chat_words_replacements[t] if t in chat_words_replacements else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(r' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(lambda x: text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>los angeles to beijing return. food low qualit...</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Xi'an</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>round to trip from hong kong to munich. the ma...</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Xi'an</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>sydney to beijing to paris then rome to beijin...</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Xi'an</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>london to sydney return via beijing. a cheap f...</td>\n",
       "      <td>2012-02-22</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Xi'an</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air China</td>\n",
       "      <td>China</td>\n",
       "      <td>beijing to shanghai. only one check to in desk...</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Xi'an</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airline Country                                             Review  \\\n",
       "0  Air China   China  los angeles to beijing return. food low qualit...   \n",
       "1  Air China   China  round to trip from hong kong to munich. the ma...   \n",
       "2  Air China   China  sydney to beijing to paris then rome to beijin...   \n",
       "3  Air China   China  london to sydney return via beijing. a cheap f...   \n",
       "4  Air China   China  beijing to shanghai. only one check to in desk...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  Seat Comfort  \\\n",
       "0     2012-01-30      Solo Leisure  Economy Class             3   \n",
       "1     2012-01-31      Solo Leisure  Economy Class             1   \n",
       "2     2012-02-03      Solo Leisure  Economy Class             2   \n",
       "3     2012-02-22      Solo Leisure  Economy Class             4   \n",
       "4     2012-02-28      Solo Leisure  Economy Class             4   \n",
       "\n",
       "   Cabin Staff Service  Food & Beverages  Inflight Entertainment  \\\n",
       "0                    2                 2                       1   \n",
       "1                    3                 1                       1   \n",
       "2                    3                 1                       2   \n",
       "3                    1                 2                       4   \n",
       "4                    4                 3                       3   \n",
       "\n",
       "   Ground Service  Value for Money Recommended   Origin Destination Sentiment  \n",
       "0               1                3           0  Beijing       Xi'an  Negative  \n",
       "1               1                3           0  Beijing       Xi'an  Negative  \n",
       "2               1                3           0  Beijing       Xi'an  Negative  \n",
       "3               3                4           0  Beijing       Xi'an  Negative  \n",
       "4               3                4           1  Beijing       Xi'an  Positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Plotting the distribution of the numerical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(15,15))\n",
    "\n",
    "for i, subplot in zip(num_col, ax.flatten()):\n",
    "    sns.distplot(df[i], ax=subplot)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the distribution of the categorical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(20,15))\n",
    "\n",
    "for i, subplot in zip(cat_col, ax.flatten()):\n",
    "    sns.countplot(x=i,data=df, ax=subplot, palette='CMRmap_r')\n",
    "    if i in ['Airline','Country']:\n",
    "        for label in subplot.get_xticklabels():\n",
    "            label.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin ['Lhr' 'Pek' 'Lax' 'S' '' 'Syd' 'Hkg' 'Fra' 'Yul' 'Sfo' 'Jfk' 'Mel' '{vg'\n",
      " 'Pvg' 'Nrt' 'Bkk' 'Mnl' 'Hel' 'Isb' 'Yvr' 'Yyc' 'Hnd' 'Vie' 'Akl' 'Icn'\n",
      " 'Can' 'Sgn' 'Ctu' 'Del' 'Dus' 'Bud' 'Iah' 'Ewr' 'Sha' 'Kul' 'Fco' 'Hkt'\n",
      " 'Cdg' 'Sin' 'Hgh' 'Nkm' 'Cph' 'Uln' 'Bcn' 'Gmp' 'Hrb' 'Hnl' 'Tpe' 'Xiy'\n",
      " 'Khn' 'Iad' 'New' 'Bom' 'Ord' 'Bhx' 'Lko' 'Rgn' 'Ccu' 'Ruh' 'Maa' 'Hyd'\n",
      " 'Goi' 'Dxb' 'Udr' 'Bxh' 'Cms' 'Vns' 'Amd' 'Ixb' 'Bho' 'Ktm' 'Ixc' 'Bbi'\n",
      " 'Mxp' 'Gay' 'Goa' 'Leh' 'Ccj' 'Jai' 'Vtz' 'Blr' 'Sjc' 'Cgk' 'Osa' 'Fuk'\n",
      " 'Bru' 'Xmn' 'Sea' 'Itm' 'Kix' 'Aus' 'Tak' 'Vce' 'Usa' 'Hi' 'Cmb' 'Szx'\n",
      " 'Yyz' 'Cgq' 'Pnh' 'Nkg' 'Ams' 'Wuz' 'Oka' 'Dps' 'Prg' 'Ckg' 'Xnn' 'Mru'\n",
      " 'Per' 'Nng' 'Tna' 'She' 'Bne' 'Lxa' 'Hak' 'Tsn' 'Foc' 'Svo' 'Nbo' 'An'\n",
      " 'Phn' 'Sjw' 'Het' 'Zuh' 'Cnx' 'Hfe' 'Vyr' 'Cgo' 'Kmg' 'Csx' 'Tao' 'Ngb'\n",
      " 'Wuh' 'Nny' 'Chc' 'Pqc' 'Wnz' 'Dlc' 'Afo' 'Kwe' 'Nai' 'Cai' 'Nce' 'Bos'\n",
      " 'Arn' 'Jnb' 'Adl' 'Bah' 'Doh' 'Cpt' 'Nyc' 'Lgw' 'Gva' 'Gla' 'Dfw' 'Mco'\n",
      " 'Lis' 'Dur' 'Ncl' 'Man' 'Khi' 'Lun' 'Acc' 'Muc' 'Mad' 'Ham' 'Kwi' 'Ist'\n",
      " 'Cmn' 'Mct' 'Osl' 'Dmm' 'Zrh' 'Dub' 'Eze' 'Jed' 'Gig' 'Mle' 'Waw' 'Ath'\n",
      " 'Otp' 'Sav' 'L' 'Det' 'Pnq' 'Cok' 'Ixj' 'Ixr' 'Tu' 'San' 'Han' 'Hkd'\n",
      " 'Cts' 'Chi' 'Bhj' 'Auh' 'Ajl' 'Rpr' 'Msp' 'Pdx' 'Tlv' 'Ngo' 'Gru' 'Sub'\n",
      " 'Lop' 'Bdo' 'Bdj' 'Tif' 'Crk' 'Edi' 'Phl' 'Dwc' 'Txl' 'Saw' 'Bey' 'Gyd'\n",
      " 'Hbe' 'Amm' 'Pen' 'Psa' 'Zag' 'Sao' 'Sof' 'Las' 'Ika' 'Atl' 'Tun' 'Mic'\n",
      " 'Dac' 'Wlg' 'Cbr' 'Bk' 'Dme' 'Atq' 'Ixz' 'Ded' 'Ixe' 'Ixg' 'Vga' 'Ixm'\n",
      " 'Dad' 'Hui' 'Cxr' 'Hph' 'Hue' 'Huế' 'Bbo' 'Gau' 'Sxr']\n",
      "Destination ['Hnd' 'Sfo' 'N' 'Jfk' 'Tpe' 'Hkg' 'Ctu' 'Tsn' 'Rk' 'Xiy' 'Bkk' 'Hrb'\n",
      " 'Mfm' 'Mel' 'Fco' 'Fra' 'Can' 'Lhr' 'Lax' 'Syd' 'Hgh' 'Hkt' 'Muc' 'Sgn'\n",
      " 'Pek' 'Mnl' 'Cgq' 'Icn' 'Del' 'Nrt' 'Bom' 'Sha' 'Bcn' 'Sin' 'Kix' 'Yvr'\n",
      " 'Cdg' 'Szx' 'Akl' 'Cnx' 'Vie' 'Iad' 'Uln' 'Gva' 'Svo' 'Iah' 'Hav' 'Arn'\n",
      " 'Khn' 'Ngo' 'Ewr' 'Ckg' 'Pvg' 'Kwl' 'Wnz' 'Cgk' 'Tao' 'Dus' 'Yul' '' 'Me'\n",
      " 'Ng' 'Leh' 'Goi' 'Hyd' 'W' 'Ccu' 'Dxb' 'Blr' 'Jdh' 'Nag' 'Cok' 'Atq'\n",
      " 'Maa' 'Ord' 'Auh' 'Bbi' 'Cjb' 'Ajl' 'Lko' 'Bdq' 'Vns' 'Amd' 'Goa' 'Diu'\n",
      " 'Bi' 'Pnq' 'Gau' 'Jai' 'Itm' 'Hkd' 'Isg' 'Dlc' 'Ngs' 'Myj' 'Sjc' 'Oka'\n",
      " 'Kul' 'She' 'Hnl' 'Jzh' 'Kmg' 'Pus' 'Wuh' 'Yyz' 'Nkg' 'Pnh' 'Ams' 'Fsz'\n",
      " 'Hfe' 'Dyg' 'Zuh' 'Rep' 'Wux' 'La' 'Cgo' 'Dps' 'Bne' 'Ktm' 'Per' 'Tna'\n",
      " 'Foc' 'Hak' 'Sjw' 'Csx' 'Nbo' 'Chc' 'Zha' 'Cxr' 'Mdg' 'Yyc' 'Adl' 'Dmm'\n",
      " 'Waw' 'Bhx' 'Cpt' 'Wn' 'Dme' 'Lgw' 'Vce' 'Man' 'Std' 'Kwi' 'Khi' 'Add'\n",
      " 'Mxp' 'Doh' 'Lhe' 'Jnb' 'Bos' 'Mru' 'Dar' 'Cmb' 'Jed' 'Cph' 'Ncl' 'Gla'\n",
      " 'Sea' 'Mct' 'Pty' 'Dub' 'Bru' 'Acc' 'Mle' 'Zrh' 'Dac' 'Trv' 'Mad' 'Lis'\n",
      " 'Cmn' 'Prg' 'Mla' 'Eze' 'Ham' 'Nce' 'Bey' 'Ath' 'Gru' 'Amm' 'Dur' 'Cai'\n",
      " 'Ceb' 'Blq' 'Isb' 'Lys' 'Um' 'Ixc' 'Re' 'Vtz' 'Ixz' 'Khh' 'Han' 'Oit'\n",
      " 'Cts' 'Hel' 'Fuk' 'San' 'Bho' 'Ded' 'Ixe' 'Ixm' 'Se' 'Atl' 'Dfw' 'Rgn'\n",
      " 'Ntr' 'Tas' 'Nan' 'Las' 'Jog' 'Sub' 'Bdj' 'Bdo' 'Tkg' 'Bah' 'Mia' 'Gyd'\n",
      " 'Edi' 'Ist' 'Syz' 'Los' 'Osl' 'Sng' 'Phl' 'Mco' 'Cnb' 'Beg' 'Dwc' 'Sof'\n",
      " 'Txl' 'Usm' 'Cbr' 'Ixg' 'Dhm' 'Udr' 'Ixb' 'Dad' 'Pqc' 'Vca' 'Hue' 'Hui'\n",
      " 'Mum']\n"
     ]
    }
   ],
   "source": [
    "for i in ['Origin','Destination']:\n",
    "    # Print the unique values in the column which have length less than 4\n",
    "    print(i,df[df[i].str.len() < 4][i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('airline_df_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
