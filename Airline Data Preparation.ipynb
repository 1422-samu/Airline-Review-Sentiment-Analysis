{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing basic libraries for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from mappings import contraction_mapping, chat_words_replacements,airport_codes\n",
    "from SW import stopwords_airline, negative_words, stopwords_extra\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from sklearn.impute import KNNImputer\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker(language='en')\n",
    "\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | Flight was punctual. But no ...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My sister, niece and mother...</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Mangalore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | My 77-year-old father was fl...</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>Not Verified |  IndiGo are a low cost airline ...</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Jaipur to Ahmedabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My flight 6e 1176 which was...</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Colombo to Mumbai via Chennai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Country                                             Review  \\\n",
       "0  indigo-airlines   India  ✅ Trip Verified | Flight was punctual. But no ...   \n",
       "1  indigo-airlines   India  ✅ Trip Verified |  My sister, niece and mother...   \n",
       "2  indigo-airlines   India  ✅ Trip Verified | My 77-year-old father was fl...   \n",
       "3  indigo-airlines   India  Not Verified |  IndiGo are a low cost airline ...   \n",
       "4  indigo-airlines   India  ✅ Trip Verified |  My flight 6e 1176 which was...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  \\\n",
       "0     2023-05-10      Solo Leisure  Economy Class   \n",
       "1     2023-05-07    Family Leisure  Economy Class   \n",
       "2     2023-04-28      Solo Leisure  Economy Class   \n",
       "3     2023-04-24      Solo Leisure  Economy Class   \n",
       "4     2023-04-22    Family Leisure  Economy Class   \n",
       "\n",
       "                           Route  Seat Comfort  Cabin Staff Service  \\\n",
       "0             Abu Dhabi to Kochi           1.0                  1.0   \n",
       "1            Mumbai to Mangalore           1.0                  NaN   \n",
       "2             Abu Dhabi to Kochi           2.0                  2.0   \n",
       "3            Jaipur to Ahmedabad           2.0                  2.0   \n",
       "4  Colombo to Mumbai via Chennai           1.0                  1.0   \n",
       "\n",
       "   Food & Beverages  Inflight Entertainment  Ground Service  Value for Money  \\\n",
       "0               1.0                     NaN             3.0              1.0   \n",
       "1               NaN                     NaN             1.0              1.0   \n",
       "2               NaN                     NaN             2.0              4.0   \n",
       "3               NaN                     NaN             2.0              3.0   \n",
       "4               1.0                     1.0             1.0              1.0   \n",
       "\n",
       "  Recommended  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3         yes  \n",
       "4          no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the csv file\n",
    "df = pd.read_csv('airline_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>10974</td>\n",
       "      <td>15047</td>\n",
       "      <td>10962</td>\n",
       "      <td>14222.000000</td>\n",
       "      <td>14208.000000</td>\n",
       "      <td>13085.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "      <td>10720.000000</td>\n",
       "      <td>15044.000000</td>\n",
       "      <td>15220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>15205</td>\n",
       "      <td>3718</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>emirates</td>\n",
       "      <td>India</td>\n",
       "      <td>Manchester to Doha and then Bangkok 24th Janua...</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Guangzhou to Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2266</td>\n",
       "      <td>3640</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>4534</td>\n",
       "      <td>11214</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.425116</td>\n",
       "      <td>3.588401</td>\n",
       "      <td>3.343676</td>\n",
       "      <td>3.432409</td>\n",
       "      <td>3.213433</td>\n",
       "      <td>3.372108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390692</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>1.439589</td>\n",
       "      <td>1.408876</td>\n",
       "      <td>1.637206</td>\n",
       "      <td>1.533749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Airline Country                                             Review  \\\n",
       "count      15220   15220                                              15220   \n",
       "unique        19       9                                              15205   \n",
       "top     emirates   India  Manchester to Doha and then Bangkok 24th Janua...   \n",
       "freq        2266    3640                                                  2   \n",
       "mean         NaN     NaN                                                NaN   \n",
       "std          NaN     NaN                                                NaN   \n",
       "min          NaN     NaN                                                NaN   \n",
       "25%          NaN     NaN                                                NaN   \n",
       "50%          NaN     NaN                                                NaN   \n",
       "75%          NaN     NaN                                                NaN   \n",
       "max          NaN     NaN                                                NaN   \n",
       "\n",
       "       Date_Published Type of Traveller      Seat Type                Route  \\\n",
       "count           15220             10974          15047                10962   \n",
       "unique           3718                 4              4                 6716   \n",
       "top        2015-01-14      Solo Leisure  Economy Class  Guangzhou to Sydney   \n",
       "freq               39              4534          11214                   30   \n",
       "mean              NaN               NaN            NaN                  NaN   \n",
       "std               NaN               NaN            NaN                  NaN   \n",
       "min               NaN               NaN            NaN                  NaN   \n",
       "25%               NaN               NaN            NaN                  NaN   \n",
       "50%               NaN               NaN            NaN                  NaN   \n",
       "75%               NaN               NaN            NaN                  NaN   \n",
       "max               NaN               NaN            NaN                  NaN   \n",
       "\n",
       "        Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "count   14222.000000         14208.000000      13085.000000   \n",
       "unique           NaN                  NaN               NaN   \n",
       "top              NaN                  NaN               NaN   \n",
       "freq             NaN                  NaN               NaN   \n",
       "mean        3.425116             3.588401          3.343676   \n",
       "std         1.390692             1.524603          1.439589   \n",
       "min         1.000000             1.000000          1.000000   \n",
       "25%         2.000000             2.000000          2.000000   \n",
       "50%         4.000000             4.000000          4.000000   \n",
       "75%         5.000000             5.000000          5.000000   \n",
       "max         5.000000             5.000000          5.000000   \n",
       "\n",
       "        Inflight Entertainment  Ground Service  Value for Money Recommended  \n",
       "count             11762.000000    10720.000000     15044.000000       15220  \n",
       "unique                     NaN             NaN              NaN           2  \n",
       "top                        NaN             NaN              NaN         yes  \n",
       "freq                       NaN             NaN              NaN        8913  \n",
       "mean                  3.432409        3.213433         3.372108         NaN  \n",
       "std                   1.408876        1.637206         1.533749         NaN  \n",
       "min                   1.000000        1.000000         1.000000         NaN  \n",
       "25%                   2.000000        1.000000         2.000000         NaN  \n",
       "50%                   4.000000        4.000000         4.000000         NaN  \n",
       "75%                   5.000000        5.000000         5.000000         NaN  \n",
       "max                   5.000000        5.000000         5.000000         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15220 entries, 0 to 15219\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Airline                 15220 non-null  object \n",
      " 1   Country                 15220 non-null  object \n",
      " 2   Review                  15220 non-null  object \n",
      " 3   Date_Published          15220 non-null  object \n",
      " 4   Type of Traveller       10974 non-null  object \n",
      " 5   Seat Type               15047 non-null  object \n",
      " 6   Route                   10962 non-null  object \n",
      " 7   Seat Comfort            14222 non-null  float64\n",
      " 8   Cabin Staff Service     14208 non-null  float64\n",
      " 9   Food & Beverages        13085 non-null  float64\n",
      " 10  Inflight Entertainment  11762 non-null  float64\n",
      " 11  Ground Service          10720 non-null  float64\n",
      " 12  Value for Money         15044 non-null  float64\n",
      " 13  Recommended             15220 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Service            4500\n",
       "Route                     4258\n",
       "Type of Traveller         4246\n",
       "Inflight Entertainment    3458\n",
       "Food & Beverages          2135\n",
       "Cabin Staff Service       1012\n",
       "Seat Comfort               998\n",
       "Value for Money            176\n",
       "Seat Type                  173\n",
       "Airline                      0\n",
       "Country                      0\n",
       "Review                       0\n",
       "Date_Published               0\n",
       "Recommended                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords Collection Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n"
     ]
    }
   ],
   "source": [
    "# Joining the stopwords to make a big stopwords collection\n",
    "\n",
    "stopwords = set(stopwords_airline).union(set(negative_words)).union(set(stopwords_extra)).union(nlp.Defaults.stop_words)\n",
    "\n",
    "# For sentiment analysis, we will need negative words as well. So, we have to remove the negative words from the stopwords list\n",
    "\n",
    "stopwords = set([word for word in stopwords if word not in negative_words])\n",
    "\n",
    "print(len(stopwords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  ['Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Ground Service', 'Value for Money']\n",
      "Categorical Columns:  ['Airline', 'Country', 'Type of Traveller', 'Seat Type', 'Recommended']\n",
      "Object Columns:  ['Airline', 'Country', 'Review', 'Date_Published', 'Type of Traveller', 'Seat Type', 'Route', 'Recommended']\n"
     ]
    }
   ],
   "source": [
    "# Separating the numerical and categorical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "obj_col = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_col = [x for x in obj_col if df[x].nunique() < 21]\n",
    "\n",
    "print('Numerical Columns: ',num_col)\n",
    "print('Categorical Columns: ',cat_col)\n",
    "print('Object Columns: ',obj_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_dataframe(df):    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    df[num_col] = imputer.fit_transform(df[num_col])\n",
    "\n",
    "    # As well as changing the data type of the numerical columns to int8\n",
    "    \n",
    "    df[num_col] = df[num_col].astype('int8')\n",
    "    \n",
    "    # Changing the Date_Published column to datetime format\n",
    "\n",
    "    df['Date_Published'] = pd.to_datetime(df['Date_Published'])\n",
    "    \n",
    "    # Sort the data by Airline and Date_Published so that we can fill the missing values in the categorical columns\n",
    "\n",
    "    df.sort_values(by=['Airline','Date_Published'],inplace=True)\n",
    "    \n",
    "    # Imputing the missing values in the categorical columns with mode using Backward fill\n",
    "    \n",
    "    df[obj_col] = df[obj_col].fillna(method='bfill')\n",
    "\n",
    "    # Mapping Recommended to 1 and Not Recommended to 0\n",
    "    \n",
    "    df['Recommended'] = df['Recommended'].replace({'yes':1,'no':0})\n",
    "\n",
    "    # As well as changing the data type of the categorical columns to category\n",
    "    \n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "    \n",
    "    # lastly dropping the duplicate records\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Preprocessing the Airline column\n",
    "\n",
    "    df['Airline'] = df['Airline'].apply(lambda x: re.sub(r'-',' ',x))\n",
    "    df['Airline'] = df['Airline'].str.title()\n",
    "\n",
    "    # df.drop(['Route'],axis=1,inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # df['Sentiment'] = df['Recommended'].map({1:'Positive',0:'Negative'})\n",
    "    \n",
    "    # Capitalizing the first letter of the Origin and Destination columns\n",
    "    \n",
    "    df.drop(['Route'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = cleanse_dataframe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAX-PEK return. Food low quality staff appeared when time for mandatory service large screen viewing on main bulkhead without sound on both trips. They were older 747s. It seems staff had something to say at irregular intervals making it hard to try and sleep but they were very good at making business transactions ignoring everyone so they could count money and look at receipts. You want a cheap very basic airline trip to China then this is the airline for you.\n",
      "\n",
      "\n",
      "Round-trip from Hong Kong to Munich. The main reason for flying Air China was no surprises the price and that was also the best and only good thing about the flight. The food was atrocious the plane worn out and the so-called entertainment system awful. The bathrooms were bad. Conclusion: everyone has their own priorities but next time I'll pay extra to fly another airline.\n",
      "\n",
      "\n",
      "Sydney-Beijing-Paris then Rome-Beijing to Sydney for a family holiday. That's four 12hr flights. As others have said price is the only advantage of this airline ($1500 AUD return to Europe from Australia during new year). The plane's facilities were poorly maintained (seat cushions slip at awkward angles TV screen falling apart or not working poor selection of entertainment toilets unkempt and food that was difficult to stomach). However it was mainly the other passengers that made it worse - yelling clearing their throats loudly rude to staff jamming their seats up and down violently and worst of all leaving the toilets a mess. Perhaps a single 12hr flight would have been tolerable but 2 of them in a row was insufferable.\n"
     ]
    }
   ],
   "source": [
    "print(df['Review'][0])\n",
    "print('\\n')\n",
    "print(df['Review'][1])\n",
    "print('\\n')\n",
    "print(df['Review'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \n",
    "    # Split on the basis of '|'\n",
    "    text = text.split('|')\n",
    "\n",
    "    # Check length and take the appropriate part\n",
    "    if len(text) == 2:\n",
    "        text = text[-1]\n",
    "    else:\n",
    "        text = text[0]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,-/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Map Airport Codes to Country Names\n",
    "    text = \" \".join([airport_codes[t] if t in airport_codes else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002500-\\U00002BEF\"  # chinese characters\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Remove special characters: newlines, tabs, etc.\n",
    "    text = re.sub(r'\\n|\\t|\\r', '', text)\n",
    "\n",
    "    # Map contractions to expansions\n",
    "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])\n",
    "\n",
    "    # Map chat words to formal words\n",
    "    text = \" \".join([chat_words_replacements[t] if t in chat_words_replacements else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(r' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Length:  729\n",
      "Minimum Review Length:  14\n",
      "Average Review Length:  130.50217019597528\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column for the length of the review\n",
    "\n",
    "df['Review_Length'] = df['Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('Maximum Review Length: ',df['Review_Length'].max())\n",
    "print('Minimum Review Length: ',df['Review_Length'].min())\n",
    "print('Average Review Length: ',df['Review_Length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los angeles beijing return food low quality staff appeared when time for mandatory service large screen viewing on main bulkhead without sound on both trips they were older 747s it seems staff had something to say at irregular intervals making it hard to try and sleep but they were very good at making business transactions ignoring everyone so they could count money and look at receipts you want a cheap very basic airline trip to china then this is the airline for you\n",
      "\n",
      "\n",
      "round trip from hong kong to munich the main reason for flying air china was no surprises the price and that was also the best and only good thing about the flight the food was atrocious the plane worn out and the so called entertainment system terrible the bathrooms were bad conclusion everyone has their own priorities but next time i will pay extra to fly another airline\n",
      "\n",
      "\n",
      "sydney beijing paris then rome beijing to sydney for a family holiday that is four 12hr flights as others have said price is the only advantage of this airline 1500 aud return to europe from australia during new year the plane's facilities were poorly maintained seat cushions slip at awkward angles tv screen falling apart or not working poor selection of entertainment toilets unkempt and food that was difficult to stomach however it was mainly the other passengers that made it worse yelling clearing their throats loudly rude to staff jamming their seats up and down violently and worst of all leaving the toilets a mess perhaps a single 12hr flight would have been tolerable but 2 of them in a row was insufferable\n"
     ]
    }
   ],
   "source": [
    "print(df['Review'][0])\n",
    "print('\\n')\n",
    "print(df['Review'][1])\n",
    "print('\\n')\n",
    "print(df['Review'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the reviews using spacy\n",
    "\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['Review'] = df['Review'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los angeles beijing return food low quality staff appear when time for mandatory service large screen view on main bulkhead without sound on both trip they be old 747 it seem staff have something to say at irregular interval make it hard to try and sleep but they be very good at make business transaction ignore everyone so they could count money and look at receipt you want a cheap very basic airline trip to china then this be the airline for you\n",
      "\n",
      "\n",
      "round trip from hong kong to munich the main reason for fly air china be no surprise the price and that be also the good and only good thing about the flight the food be atrocious the plane wear out and the so call entertainment system terrible the bathroom be bad conclusion everyone have their own priority but next time I will pay extra to fly another airline\n",
      "\n",
      "\n",
      "sydney beijing paris then rome beijing to sydney for a family holiday that be four 12hr flight as other have say price be the only advantage of this airline 1500 aud return to europe from australia during new year the plane 's facility be poorly maintain seat cushion slip at awkward angle tv screen fall apart or not work poor selection of entertainment toilet unkempt and food that be difficult to stomach however it be mainly the other passenger that make it bad yell clear their throat loudly rude to staff jam their seat up and down violently and bad of all leave the toilet a mess perhaps a single 12hr flight would have be tolerable but 2 of they in a row be insufferable\n"
     ]
    }
   ],
   "source": [
    "print(df['Review'][0])\n",
    "print('\\n')\n",
    "print(df['Review'][1])\n",
    "print('\\n')\n",
    "print(df['Review'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remvoing the stopwords from the reviews\n",
    "\n",
    "df['Cleaned_Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Length:  334\n",
      "Minimum Review Length:  5\n",
      "Average Review Length:  58.462120215704324\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column for the length of the review\n",
    "\n",
    "df['Cleaned_Review_Length'] = df['Cleaned_Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('Maximum Review Length: ',df['Cleaned_Review_Length'].max())\n",
    "print('Minimum Review Length: ',df['Cleaned_Review_Length'].min())\n",
    "print('Average Review Length: ',df['Cleaned_Review_Length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"truly astonishing world 's good airline for a reason great service lot of extra provide on time\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the reviews with length 6\n",
    "\n",
    "df[df['Cleaned_Review_Length'] == 5]['Review'][10722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astonishing reason service extra time'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Cleaned_Review_Length'] == 5]['Cleaned_Review'][10722]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Plotting the distribution of the numerical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(15,15))\n",
    "\n",
    "for i, subplot in zip(num_col, ax.flatten()):\n",
    "    sns.distplot(df[i], ax=subplot)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the distribution of the categorical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(20,15))\n",
    "\n",
    "for i, subplot in zip(cat_col, ax.flatten()):\n",
    "    sns.countplot(x=i,data=df, ax=subplot, palette='CMRmap_r')\n",
    "    if i in ['Airline','Country']:\n",
    "        for label in subplot.get_xticklabels():\n",
    "            label.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('airline_df_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
