{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing basic libraries for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from mappings import contraction_mapping, chat_words_replacements,airport_codes,origin_loc_mapping,dest_loc_mapping\n",
    "sns.set_theme()\n",
    "\n",
    "# Setting the best style for the plots in seaborn\n",
    "\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | Flight was punctual. But no ...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My sister, niece and mother...</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Mangalore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified | My 77-year-old father was fl...</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Abu Dhabi to Kochi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>Not Verified |  IndiGo are a low cost airline ...</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Jaipur to Ahmedabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigo-airlines</td>\n",
       "      <td>India</td>\n",
       "      <td>✅ Trip Verified |  My flight 6e 1176 which was...</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Colombo to Mumbai via Chennai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Country                                             Review  \\\n",
       "0  indigo-airlines   India  ✅ Trip Verified | Flight was punctual. But no ...   \n",
       "1  indigo-airlines   India  ✅ Trip Verified |  My sister, niece and mother...   \n",
       "2  indigo-airlines   India  ✅ Trip Verified | My 77-year-old father was fl...   \n",
       "3  indigo-airlines   India  Not Verified |  IndiGo are a low cost airline ...   \n",
       "4  indigo-airlines   India  ✅ Trip Verified |  My flight 6e 1176 which was...   \n",
       "\n",
       "  Date_Published Type of Traveller      Seat Type  \\\n",
       "0     2023-05-10      Solo Leisure  Economy Class   \n",
       "1     2023-05-07    Family Leisure  Economy Class   \n",
       "2     2023-04-28      Solo Leisure  Economy Class   \n",
       "3     2023-04-24      Solo Leisure  Economy Class   \n",
       "4     2023-04-22    Family Leisure  Economy Class   \n",
       "\n",
       "                           Route  Seat Comfort  Cabin Staff Service  \\\n",
       "0             Abu Dhabi to Kochi           1.0                  1.0   \n",
       "1            Mumbai to Mangalore           1.0                  NaN   \n",
       "2             Abu Dhabi to Kochi           2.0                  2.0   \n",
       "3            Jaipur to Ahmedabad           2.0                  2.0   \n",
       "4  Colombo to Mumbai via Chennai           1.0                  1.0   \n",
       "\n",
       "   Food & Beverages  Inflight Entertainment  Ground Service  Value for Money  \\\n",
       "0               1.0                     NaN             3.0              1.0   \n",
       "1               NaN                     NaN             1.0              1.0   \n",
       "2               NaN                     NaN             2.0              4.0   \n",
       "3               NaN                     NaN             2.0              3.0   \n",
       "4               1.0                     1.0             1.0              1.0   \n",
       "\n",
       "  Recommended  \n",
       "0          no  \n",
       "1          no  \n",
       "2          no  \n",
       "3         yes  \n",
       "4          no  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the csv file\n",
    "df = pd.read_csv('airline_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Country</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>15220</td>\n",
       "      <td>10974</td>\n",
       "      <td>15047</td>\n",
       "      <td>10962</td>\n",
       "      <td>14222.000000</td>\n",
       "      <td>14208.000000</td>\n",
       "      <td>13085.000000</td>\n",
       "      <td>11762.000000</td>\n",
       "      <td>10720.000000</td>\n",
       "      <td>15044.000000</td>\n",
       "      <td>15220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>15205</td>\n",
       "      <td>3718</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>emirates</td>\n",
       "      <td>India</td>\n",
       "      <td>Manchester to Doha and then Bangkok 24th Janua...</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Guangzhou to Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2266</td>\n",
       "      <td>3640</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>4534</td>\n",
       "      <td>11214</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.425116</td>\n",
       "      <td>3.588401</td>\n",
       "      <td>3.343676</td>\n",
       "      <td>3.432409</td>\n",
       "      <td>3.213433</td>\n",
       "      <td>3.372108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390692</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>1.439589</td>\n",
       "      <td>1.408876</td>\n",
       "      <td>1.637206</td>\n",
       "      <td>1.533749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Airline Country                                             Review  \\\n",
       "count      15220   15220                                              15220   \n",
       "unique        19       9                                              15205   \n",
       "top     emirates   India  Manchester to Doha and then Bangkok 24th Janua...   \n",
       "freq        2266    3640                                                  2   \n",
       "mean         NaN     NaN                                                NaN   \n",
       "std          NaN     NaN                                                NaN   \n",
       "min          NaN     NaN                                                NaN   \n",
       "25%          NaN     NaN                                                NaN   \n",
       "50%          NaN     NaN                                                NaN   \n",
       "75%          NaN     NaN                                                NaN   \n",
       "max          NaN     NaN                                                NaN   \n",
       "\n",
       "       Date_Published Type of Traveller      Seat Type                Route  \\\n",
       "count           15220             10974          15047                10962   \n",
       "unique           3718                 4              4                 6716   \n",
       "top        2015-01-14      Solo Leisure  Economy Class  Guangzhou to Sydney   \n",
       "freq               39              4534          11214                   30   \n",
       "mean              NaN               NaN            NaN                  NaN   \n",
       "std               NaN               NaN            NaN                  NaN   \n",
       "min               NaN               NaN            NaN                  NaN   \n",
       "25%               NaN               NaN            NaN                  NaN   \n",
       "50%               NaN               NaN            NaN                  NaN   \n",
       "75%               NaN               NaN            NaN                  NaN   \n",
       "max               NaN               NaN            NaN                  NaN   \n",
       "\n",
       "        Seat Comfort  Cabin Staff Service  Food & Beverages  \\\n",
       "count   14222.000000         14208.000000      13085.000000   \n",
       "unique           NaN                  NaN               NaN   \n",
       "top              NaN                  NaN               NaN   \n",
       "freq             NaN                  NaN               NaN   \n",
       "mean        3.425116             3.588401          3.343676   \n",
       "std         1.390692             1.524603          1.439589   \n",
       "min         1.000000             1.000000          1.000000   \n",
       "25%         2.000000             2.000000          2.000000   \n",
       "50%         4.000000             4.000000          4.000000   \n",
       "75%         5.000000             5.000000          5.000000   \n",
       "max         5.000000             5.000000          5.000000   \n",
       "\n",
       "        Inflight Entertainment  Ground Service  Value for Money Recommended  \n",
       "count             11762.000000    10720.000000     15044.000000       15220  \n",
       "unique                     NaN             NaN              NaN           2  \n",
       "top                        NaN             NaN              NaN         yes  \n",
       "freq                       NaN             NaN              NaN        8913  \n",
       "mean                  3.432409        3.213433         3.372108         NaN  \n",
       "std                   1.408876        1.637206         1.533749         NaN  \n",
       "min                   1.000000        1.000000         1.000000         NaN  \n",
       "25%                   2.000000        1.000000         2.000000         NaN  \n",
       "50%                   4.000000        4.000000         4.000000         NaN  \n",
       "75%                   5.000000        5.000000         5.000000         NaN  \n",
       "max                   5.000000        5.000000         5.000000         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15220 entries, 0 to 15219\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Airline                 15220 non-null  object \n",
      " 1   Country                 15220 non-null  object \n",
      " 2   Review                  15220 non-null  object \n",
      " 3   Date_Published          15220 non-null  object \n",
      " 4   Type of Traveller       10974 non-null  object \n",
      " 5   Seat Type               15047 non-null  object \n",
      " 6   Route                   10962 non-null  object \n",
      " 7   Seat Comfort            14222 non-null  float64\n",
      " 8   Cabin Staff Service     14208 non-null  float64\n",
      " 9   Food & Beverages        13085 non-null  float64\n",
      " 10  Inflight Entertainment  11762 non-null  float64\n",
      " 11  Ground Service          10720 non-null  float64\n",
      " 12  Value for Money         15044 non-null  float64\n",
      " 13  Recommended             15220 non-null  object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Service            4500\n",
       "Route                     4258\n",
       "Type of Traveller         4246\n",
       "Inflight Entertainment    3458\n",
       "Food & Beverages          2135\n",
       "Cabin Staff Service       1012\n",
       "Seat Comfort               998\n",
       "Value for Money            176\n",
       "Seat Type                  173\n",
       "Airline                      0\n",
       "Country                      0\n",
       "Review                       0\n",
       "Date_Published               0\n",
       "Recommended                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  ['Seat Comfort', 'Cabin Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Ground Service', 'Value for Money']\n",
      "Categorical Columns:  ['Airline', 'Country', 'Type of Traveller', 'Seat Type', 'Recommended']\n"
     ]
    }
   ],
   "source": [
    "# Separating the numerical and categorical columns\n",
    "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
    "obj_col = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_col = [x for x in obj_col if df[x].nunique() < 21]\n",
    "\n",
    "print('Numerical Columns: ',num_col)\n",
    "print('Categorical Columns: ',cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "findall() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 101\u001b[0m\n\u001b[0;32m     97\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: dest_loc_mapping[x] \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m dest_loc_mapping\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m x)\n\u001b[0;32m     99\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m--> 101\u001b[0m df \u001b[39m=\u001b[39m cleanse_data(df)\n",
      "Cell \u001b[1;32mIn[14], line 72\u001b[0m, in \u001b[0;36mcleanse_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     68\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcapitalize()\n\u001b[0;32m     70\u001b[0m \u001b[39m# Getting the Destination from the Reviews if found then replace the Destination column with the extracted Destination other wise keep the Destination column as it is\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mReview\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: re\u001b[39m.\u001b[39;49mfindall(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mto\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms+([A-Za-z\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms-]+)\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[39m# lastly dropping the\u001b[39;00m\n\u001b[0;32m     76\u001b[0m df\u001b[39m.\u001b[39mdrop_duplicates(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\Github\\Airline-Review-Sentiment-Analysis\\.venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[14], line 72\u001b[0m, in \u001b[0;36mcleanse_data.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     68\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcapitalize()\n\u001b[0;32m     70\u001b[0m \u001b[39m# Getting the Destination from the Reviews if found then replace the Destination column with the extracted Destination other wise keep the Destination column as it is\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mDestination\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mReview\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39;49mfindall(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mto\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms+([A-Za-z\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms-]+)\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[39m# lastly dropping the\u001b[39;00m\n\u001b[0;32m     76\u001b[0m df\u001b[39m.\u001b[39mdrop_duplicates(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: findall() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "# Imputing the missing values in the numerical columns with mode using simple imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def cleanse_data(df):    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    df[num_col] = imputer.fit_transform(df[num_col])\n",
    "\n",
    "    # As well as changing the data type of the numerical columns to int8\n",
    "    \n",
    "    df[num_col] = df[num_col].astype('int8')\n",
    "    \n",
    "    # Changing the Date_Published column to datetime format\n",
    "\n",
    "    df['Date_Published'] = pd.to_datetime(df['Date_Published'])\n",
    "    \n",
    "    # Sort the data by Airline and Date_Published so that we can fill the missing values in the categorical columns\n",
    "\n",
    "    df.sort_values(by=['Airline','Date_Published'],inplace=True)\n",
    "    \n",
    "    # Finding Routes from the Reviews\n",
    "    \n",
    "    \n",
    "    # Imputing the missing values in the categorical columns with mode using Backward fill\n",
    "    \n",
    "    df[obj_col] = df[obj_col].fillna(method='bfill')\n",
    "\n",
    "    # Mapping Recommended to 1 and Not Recommended to 0\n",
    "    \n",
    "    df['Recommended'] = df['Recommended'].map({'yes':1,'no':0})\n",
    "\n",
    "    # As well as changing the data type of the categorical columns to category\n",
    "    \n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "\n",
    "    # Cleaning the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].apply(lambda x: x.split('via')[0].strip() if 'via' in x else x.strip())\n",
    "\n",
    "    # Dropping the record where the route is Melbourne, Chennai and Zurich\n",
    "    \n",
    "    df.drop(df[df['Route'] == 'Melbourne'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Chennai'].index, inplace=True)\n",
    "    df.drop(df[df['Route'] == 'Zurich'].index, inplace=True)\n",
    "\n",
    "    # Small casing the Route column\n",
    "\n",
    "    df['Route'] = df['Route'].str.lower()\n",
    "    \n",
    "    # ro, to, yo, - will be used for splitting the route column\n",
    "\n",
    "    # Splitting the Route column into Origin and Destination\n",
    "\n",
    "    # Origin Extraction\n",
    "\n",
    "    df['Origin'] = df['Route'].apply(lambda x: x.split('ro')[0].strip() if 'ro' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('to')[0].strip() if 'to' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('yo')[0].strip() if 'yo' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].apply(lambda x: x.split('-')[0].strip() if '-' in x else x.strip())\n",
    "    df['Origin'] = df['Origin'].str.capitalize()\n",
    "\n",
    "    # Destination Extraction\n",
    "\n",
    "    df['Destination'] = df['Route'].apply(lambda x: x.split('ro')[-1].strip() if 'ro' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('to')[-1].strip() if 'to' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('yo')[-1].strip() if 'yo' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].apply(lambda x: x.split('-')[-1].strip() if '-' in x else x.strip())\n",
    "    df['Destination'] = df['Destination'].str.capitalize()\n",
    "    \n",
    "    # Getting the Destination from the Reviews if found then replace the Destination column with the extracted Destination other wise keep the Destination column as it is\n",
    "    \n",
    "    df['Destination'] = df['Review'].apply(lambda x: re.findall(r\"to\\s+([A-Za-z\\s-]+)\")).astype('str')\n",
    "\n",
    "    # lastly dropping the\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Preprocessing the Airline column\n",
    "\n",
    "    df['Airline'] = df['Airline'].apply(lambda x: re.sub(r'-',' ',x))\n",
    "    df['Airline'] = df['Airline'].str.title()\n",
    "\n",
    "    # df.drop(['Route'],axis=1,inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    df['Sentiment'] = df['Recommended'].map({1:'Positive',0:'Negative'})\n",
    "    \n",
    "    # Capitalizing the first letter of the Origin and Destination columns\n",
    "    \n",
    "    df['Origin'] = df['Origin'].str.title()\n",
    "    df['Destination'] = df['Destination'].str.title()\n",
    "    \n",
    "    # # Mapping the Origin and Destination columns to their respective countries without map function\n",
    "    \n",
    "    df['Origin'] = df['Origin'].apply(lambda x: origin_loc_mapping[x] if x in origin_loc_mapping.keys() else x)    \n",
    "    df['Destination'] = df['Destination'].apply(lambda x: dest_loc_mapping[x] if x in dest_loc_mapping.keys() else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = cleanse_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Origin'].nunique())\n",
    "print(df['Destination'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \n",
    "    # Substitute - with 'to'\n",
    "    \n",
    "    text = re.sub(r'-',' to ',text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Map Airport Codes to Country Names\n",
    "    text = \" \".join([airport_codes[t] if t in airport_codes else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002500-\\U00002BEF\"  # chinese characters\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        \"\\u3030\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # Split on the basis of '|'\n",
    "    text = text.split('|')\n",
    "\n",
    "    # Check length and take the appropriate part\n",
    "    if len(text) == 2:\n",
    "        text = text[-1]\n",
    "    else:\n",
    "        text = text[0]\n",
    "\n",
    "    # Remove special characters: newlines, tabs, etc.\n",
    "    text = re.sub(r'\\n|\\t|\\r', '', text)\n",
    "\n",
    "    # Map contractions to expansions\n",
    "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])\n",
    "\n",
    "    # Map chat words to formal words\n",
    "    text = \" \".join([chat_words_replacements[t] if t in chat_words_replacements else t for t in text.split(\" \")])\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = html_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    punc = re.compile(r'[\"#$%&()*+,/:;<=>?@[\\]^_`{|}~]')\n",
    "    text = punc.sub(r' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(r' ', text)\n",
    "\n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(lambda x: text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Plotting the distribution of the numerical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(15,15))\n",
    "\n",
    "for i, subplot in zip(num_col, ax.flatten()):\n",
    "    sns.distplot(df[i], ax=subplot)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the distribution of the categorical columns after imputing the missing values\n",
    "\n",
    "fig , ax = plt.subplots(3,2,figsize=(20,15))\n",
    "\n",
    "for i, subplot in zip(cat_col, ax.flatten()):\n",
    "    sns.countplot(x=i,data=df, ax=subplot, palette='CMRmap_r')\n",
    "    if i in ['Airline','Country']:\n",
    "        for label in subplot.get_xticklabels():\n",
    "            label.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Origin_Country','Destination']:\n",
    "    # Print the unique values in the columns\n",
    "    print(i,df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('airline_df_cleaned.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
