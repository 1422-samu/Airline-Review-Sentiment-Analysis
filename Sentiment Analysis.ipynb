{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing libraries for sentiment analysis LSTM model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "\n",
    "data = pd.read_csv('airline_df_nlped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review2</th>\n",
       "      <th>Cleaned_Review2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>Air China</td>\n",
       "      <td>los angeles beijing return food low quality st...</td>\n",
       "      <td>los angeles beijing return food quality staff ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>los angeles beijing return food low quality st...</td>\n",
       "      <td>los angeles beijing return food quality staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>Air China</td>\n",
       "      <td>round trip from hong kong to munich the main r...</td>\n",
       "      <td>round trip hong kong munich main reason fly ai...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>round trip from hong kong to munich the main r...</td>\n",
       "      <td>round trip hong kong munich main reason fly ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Air China</td>\n",
       "      <td>sydney beijing paris then rome beijing to sydn...</td>\n",
       "      <td>sydney beijing paris rome beijing sydney famil...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>sydney beijing paris then rome beijing to sydn...</td>\n",
       "      <td>sydney beijing paris rome beijing sydney famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>Air China</td>\n",
       "      <td>london to sydney return via beijing a cheap fl...</td>\n",
       "      <td>london sydney return beijing cheap flight live...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>london to sydney return via beijing a cheap fl...</td>\n",
       "      <td>london sydney return beijing cheap flight live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>Air China</td>\n",
       "      <td>beijing to shanghai only one check in desk for...</td>\n",
       "      <td>beijing shanghai check desk standby passenger ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>beijing to shanghai only one check in desk for...</td>\n",
       "      <td>beijing shanghai check desk standby passenger ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country    Airline                                             Review  \\\n",
       "0   China  Air China  los angeles beijing return food low quality st...   \n",
       "1   China  Air China  round trip from hong kong to munich the main r...   \n",
       "2   China  Air China  sydney beijing paris then rome beijing to sydn...   \n",
       "3   China  Air China  london to sydney return via beijing a cheap fl...   \n",
       "4   China  Air China  beijing to shanghai only one check in desk for...   \n",
       "\n",
       "                                      Cleaned_Review Sentiment  \\\n",
       "0  los angeles beijing return food quality staff ...  Negative   \n",
       "1  round trip hong kong munich main reason fly ai...  Negative   \n",
       "2  sydney beijing paris rome beijing sydney famil...  Negative   \n",
       "3  london sydney return beijing cheap flight live...  Negative   \n",
       "4  beijing shanghai check desk standby passenger ...  Positive   \n",
       "\n",
       "                                             Review2  \\\n",
       "0  los angeles beijing return food low quality st...   \n",
       "1  round trip from hong kong to munich the main r...   \n",
       "2  sydney beijing paris then rome beijing to sydn...   \n",
       "3  london to sydney return via beijing a cheap fl...   \n",
       "4  beijing to shanghai only one check in desk for...   \n",
       "\n",
       "                                     Cleaned_Review2  \n",
       "0  los angeles beijing return food quality staff ...  \n",
       "1  round trip hong kong munich main reason fly ai...  \n",
       "2  sydney beijing paris rome beijing sydney famil...  \n",
       "3  london sydney return beijing cheap flight live...  \n",
       "4  beijing shanghai check desk standby passenger ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15206, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los angeles beijing return food low quality staff appear when time for mandatory service large screen view on main bulkhead without sound on both trip they be old it seem staff have something to say at irregular interval make it hard to try and sleep but they be very good at make business transaction ignore everyone so they could count money and look at receipt you want a cheap very basic airline trip to china then this be the airline for you'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los angeles beijing return food quality staff appear time mandatory service large screen view main bulkhead sound trip staff irregular interval hard sleep business transaction ignore count money receipt cheap basic trip china'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cleaned_Review2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country            0\n",
       "Airline            0\n",
       "Review             0\n",
       "Cleaned_Review     0\n",
       "Review2            0\n",
       "Cleaned_Review2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "X = data['Review2']\n",
    "\n",
    "y = data['Sentiment']\n",
    "\n",
    "y = y.map({'Positive':1,'Negative':0,})\n",
    "\n",
    "# cv = CountVectorizer(max_features=10000,ngram_range=(1,1),stop_words='english')\n",
    "\n",
    "# X = cv.fit_transform(X).toarray()\n",
    "\n",
    "vec = TfidfVectorizer(max_features=10000,ngram_range=(1,1),stop_words='english')\n",
    "\n",
    "X = vec.fit_transform(X).toarray()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  GNB\n",
      "Confusion Matrix: \n",
      " [[960 300]\n",
      " [786 996]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.76      0.64      1260\n",
      "           1       0.77      0.56      0.65      1782\n",
      "\n",
      "    accuracy                           0.64      3042\n",
      "   macro avg       0.66      0.66      0.64      3042\n",
      "weighted avg       0.68      0.64      0.64      3042\n",
      "\n",
      "Model:  BNB\n",
      "Confusion Matrix: \n",
      " [[ 994  266]\n",
      " [ 154 1628]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1260\n",
      "           1       0.86      0.91      0.89      1782\n",
      "\n",
      "    accuracy                           0.86      3042\n",
      "   macro avg       0.86      0.85      0.86      3042\n",
      "weighted avg       0.86      0.86      0.86      3042\n",
      "\n",
      "Model:  MNB\n",
      "Confusion Matrix: \n",
      " [[ 935  325]\n",
      " [ 100 1682]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81      1260\n",
      "           1       0.84      0.94      0.89      1782\n",
      "\n",
      "    accuracy                           0.86      3042\n",
      "   macro avg       0.87      0.84      0.85      3042\n",
      "weighted avg       0.87      0.86      0.86      3042\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNB</td>\n",
       "      <td>0.642998</td>\n",
       "      <td>0.677937</td>\n",
       "      <td>0.642998</td>\n",
       "      <td>0.643673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNB</td>\n",
       "      <td>0.861933</td>\n",
       "      <td>0.862165</td>\n",
       "      <td>0.861933</td>\n",
       "      <td>0.860825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.860289</td>\n",
       "      <td>0.865120</td>\n",
       "      <td>0.860289</td>\n",
       "      <td>0.857589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Precision    Recall  F1 Score\n",
       "0   GNB  0.642998   0.677937  0.642998  0.643673\n",
       "1   BNB  0.861933   0.862165  0.861933  0.860825\n",
       "2   MNB  0.860289   0.865120  0.860289  0.857589"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "models = [('GNB',GaussianNB()),('BNB',BernoulliNB()),('MNB',MultinomialNB())]\n",
    "results = pd.DataFrame(columns=['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "\n",
    "for name,model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    prec = precision_score(y_test,y_pred,average='weighted')\n",
    "    rec = recall_score(y_test,y_pred,average='weighted')\n",
    "    f1 = f1_score(y_test,y_pred,average='weighted')\n",
    "    # roc_auc = roc_auc_score(y_test,y_pred)\n",
    "    # Adding the results to the dataframe without appending\n",
    "    results.loc[len(results)] = [name,acc,prec,rec,f1]\n",
    "    print('Model: ',name)\n",
    "    print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))\n",
    "    print('Classification Report: \\n',classification_report(y_test,y_pred))\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a word2vec model for sentiment analysis\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Creating a list of reviews_for_word2vec\n",
    "\n",
    "reviews_for_word2vec = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    reviews_for_word2vec.append(data['Review2'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15206, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a word2vec model\n",
    "\n",
    "word2vec_model = Word2Vec(reviews_for_word2vec,min_count=1,vector_size=200,window=5,workers=4)\n",
    "\n",
    "# Creating a list of vectors for each review\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for i in range(len(reviews_for_word2vec)):\n",
    "    vectors.append(np.sum(word2vec_model.wv[reviews_for_word2vec[i]],axis=0))\n",
    "    \n",
    "vectors = np.array(vectors)\n",
    "\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.870809</td>\n",
       "      <td>0.882645</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.890742</td>\n",
       "      <td>0.864971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.865549</td>\n",
       "      <td>0.876164</td>\n",
       "      <td>0.897306</td>\n",
       "      <td>0.886609</td>\n",
       "      <td>0.858971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBC</th>\n",
       "      <td>0.862919</td>\n",
       "      <td>0.873155</td>\n",
       "      <td>0.896184</td>\n",
       "      <td>0.884520</td>\n",
       "      <td>0.856029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.868392</td>\n",
       "      <td>0.884961</td>\n",
       "      <td>0.876598</td>\n",
       "      <td>0.847639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>0.836292</td>\n",
       "      <td>0.847403</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.862810</td>\n",
       "      <td>0.827489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETC</th>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.840381</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.865542</td>\n",
       "      <td>0.826287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.819198</td>\n",
       "      <td>0.823190</td>\n",
       "      <td>0.880471</td>\n",
       "      <td>0.850868</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNB</th>\n",
       "      <td>0.793557</td>\n",
       "      <td>0.842230</td>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.818916</td>\n",
       "      <td>0.792873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.693294</td>\n",
       "      <td>0.686922</td>\n",
       "      <td>0.875421</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.655568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  Precision    Recall  F1 Score  ROC AUC Score\n",
       "Model                                                        \n",
       "LR     0.870809   0.882645  0.898990  0.890742       0.864971\n",
       "SVC    0.865549   0.876164  0.897306  0.886609       0.858971\n",
       "CBC    0.862919   0.873155  0.896184  0.884520       0.856029\n",
       "XGB    0.854043   0.868392  0.884961  0.876598       0.847639\n",
       "RFC    0.836292   0.847403  0.878788  0.862810       0.827489\n",
       "ETC    0.837607   0.840381  0.892256  0.865542       0.826287\n",
       "KNN    0.819198   0.823190  0.880471  0.850868       0.806506\n",
       "BNB    0.793557   0.842230  0.796857  0.818916       0.792873\n",
       "GNB    0.693294   0.686922  0.875421  0.769800       0.655568"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building\n",
    "\n",
    "X = vectors\n",
    "\n",
    "y = data[\"Sentiment\"]\n",
    "\n",
    "y = y.map({\"Positive\": 1, \"Negative\": 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "models = [\n",
    "    (\"GNB\", GaussianNB()),\n",
    "    (\"BNB\", BernoulliNB()),\n",
    "    (\"SVC\", SVC(random_state=101)),\n",
    "    (\"RFC\", RandomForestClassifier(random_state=101)),\n",
    "    (\"ETC\", ExtraTreesClassifier(random_state=101, n_jobs=-1)),\n",
    "    (\"LR\", LogisticRegression(n_jobs=-1)),\n",
    "    (\"KNN\", KNeighborsClassifier(n_jobs=-1)),\n",
    "    (\"XGB\", XGBClassifier(random_state=101, n_jobs=-1)),\n",
    "    (\"CBC\", CatBoostClassifier(random_state=101, verbose=0)),\n",
    "]\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC Score\"]\n",
    ")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # Adding the results to the dataframe without appending\n",
    "    results.loc[len(results)] = [name, acc, prec, rec, f1, roc_auc]\n",
    "\n",
    "results.set_index(\"Model\").sort_values(by=\"ROC AUC Score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
